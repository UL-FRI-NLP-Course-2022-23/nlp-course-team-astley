{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_map = {}\n",
    "\n",
    "def add_word(word, score, key):\n",
    "    global scores_map\n",
    "    if word in scores_map:\n",
    "        scores_map[word][key] = score\n",
    "    else:\n",
    "        scores_map[word] = {key:score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\"positive-words.txt\"]\n",
    "for fpath in scores:\n",
    "    path = \"./score_sets/\"+fpath\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            add_word(line.lower().strip(), 3, \"txt\")\n",
    "\n",
    "scores = [\"negative-words.txt\"]\n",
    "for fpath in scores:\n",
    "    path = \"./score_sets/\"+fpath\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            add_word(line.lower().strip(), -3, \"txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\"SWN.txt\"]\n",
    "\n",
    "\n",
    "for fpath in scores:\n",
    "    # pattern = r\"word1=(.*?)\\spos1\"\n",
    "    # pattern2 = r\"priorpolarity=(.*?)\\n\"\n",
    "    path = \"./score_sets/\"+fpath\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            fields = line.strip().split(\"\\t\")\n",
    "            # POS\tID\tPosScore\tNegScore\tSynsetTerms\tGloss\n",
    "            score = 1 - (float(fields[2]) + float(fields[3]))\n",
    "            for key in fields[4].split():\n",
    "                wordd = key.split(\"#\")[0].lower()\n",
    "                add_word(wordd, score, \"swn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\"subjcluesl.txt\"]\n",
    "for fpath in scores:\n",
    "    pattern = r\"word1=(.*?)\\spos1\"\n",
    "    pattern2 = r\"priorpolarity=(.*?)\\n\"\n",
    "    path = \"./score_sets/\"+fpath\n",
    "    with open(path, 'r') as file:\n",
    "        for line in file:\n",
    "            match2 = re.search(pattern2, line)\n",
    "            match = re.search(pattern, line)\n",
    "            word = match.group(1)\n",
    "            word2 = match2.group(1)[:3]\n",
    "            if(word2 == \"pos\"):\n",
    "                add_word(word.lower(),3, \"sub\")\n",
    "            elif(word2 == \"neg\"):\n",
    "                add_word(word.lower(),-3, \"sub\")\n",
    "            elif(word2 == \"neu\"):\n",
    "                add_word(word.lower(),0, \"sub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"./score_sets/AFINN.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split(\"\\t\")\n",
    "        add_word(fields[0].lower(),fields[1], \"affin\")\n",
    "        word = fields[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dictionary(dictionary, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(dictionary, file)\n",
    "\n",
    "def read_dictionary(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        dictionary = json.load(file)\n",
    "    return dictionary\n",
    "\n",
    "# write_dictionary(scores_map, \"./sets/scores_map.json\")\n",
    "scores_map = read_dictionary(\"./sets/scores_map.json\")\n",
    "assert len(scores_map) == 149567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_word_occurrences(file_path):\n",
    "    word_counts = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            word = line.strip().lower()\n",
    "            if word in word_counts:\n",
    "                word_counts[word] += 1\n",
    "            else:\n",
    "                word_counts[word] = 1\n",
    "    return word_counts\n",
    "\n",
    "def find_common_keys(dict1, dict2):\n",
    "    common_keys = []\n",
    "    new_map = {}\n",
    "\n",
    "    for key in dict2.keys():\n",
    "        if key in dict1:\n",
    "            common_keys.append(key)\n",
    "        else:\n",
    "            new_map[key] = dict2[key]\n",
    "    return common_keys, new_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "517 700 84\n",
      "877 911 95\n"
     ]
    }
   ],
   "source": [
    "file_pos = \"./sets/pos_traits.txt\"\n",
    "file_neg = \"./sets/neg_traits.txt\"\n",
    "file_neu = \"./sets/neu_traits.txt\"\n",
    "files_new = [\"./sets/traits.txt\", \"./sets/traits2.txt\", \"./sets/traits3.txt\", \"./sets/traits4.txt\", \"./sets/traits5.txt\", \"./sets/traits6.txt\"]\n",
    "\n",
    "pos_occ = count_word_occurrences(file_pos)\n",
    "neg_occ = count_word_occurrences(file_neg)\n",
    "neu_occ = count_word_occurrences(file_neu)\n",
    "undone = []\n",
    "print(len(pos_occ),len(neg_occ),len(neu_occ))\n",
    "\n",
    "def find_label(sc):\n",
    "    if(\"affin\" in sc):\n",
    "        lab = sc[\"affin\"]\n",
    "    elif(\"sub\" in sc):\n",
    "        lab = sc[\"sub\"]\n",
    "    elif(\"txt\" in sc):\n",
    "        lab = sc[\"txt\"]\n",
    "    elif(\"swn\" in sc):\n",
    "        lab = sc[\"swn\"]\n",
    "\n",
    "    return float(lab)\n",
    "\n",
    "neu_last = {}\n",
    "pos_last = {}\n",
    "neg_last = {}\n",
    "\n",
    "for file_new in files_new:\n",
    "    new_occ = count_word_occurrences(file_new)\n",
    "\n",
    "    _, new_map = find_common_keys(pos_occ, new_occ)\n",
    "    _, new_map = find_common_keys(neg_occ, new_map)\n",
    "    _, new_map = find_common_keys(neu_occ, new_map)\n",
    "\n",
    "    for key in new_map:\n",
    "        if key in scores_map:\n",
    "            label = find_label(scores_map[key])\n",
    "\n",
    "            if(label == 0):\n",
    "                neu_occ[key] = 1\n",
    "            if(label > 0):\n",
    "                pos_occ[key] = 1\n",
    "            if(label < 0):\n",
    "                neg_occ[key] = 1\n",
    "        else:\n",
    "            undone.append(key)\n",
    "print(len(pos_occ),len(neg_occ),len(neu_occ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827 1030 103\n"
     ]
    }
   ],
   "source": [
    "path = \"./sets/unfinished.txt\"\n",
    "with open(path, 'r') as file:\n",
    "    for line in file:\n",
    "        fields = line.split(\",\")\n",
    "        key = fields[0].strip()\n",
    "        score = float(fields[1].strip())\n",
    "        if(score == 0):\n",
    "            if key in neu_occ:\n",
    "                neu_occ[key] += 1\n",
    "            else:    \n",
    "                neu_occ[key] = 1\n",
    "            if key in pos_occ:\n",
    "                del pos_occ[key]\n",
    "            if key in neg_occ:\n",
    "                del neg_occ[key]\n",
    "        elif(score > 0):\n",
    "            if key in pos_occ:\n",
    "                pos_occ[key] += 1\n",
    "            else:    \n",
    "                pos_occ[key] = 1\n",
    "            if key in neu_occ:\n",
    "                del neu_occ[key]\n",
    "            if key in neg_occ:\n",
    "                del neg_occ[key]\n",
    "        elif(score < 0):\n",
    "            if key in neg_occ:\n",
    "                neg_occ[key] += 1\n",
    "            else:    \n",
    "                neg_occ[key] = 1\n",
    "            if key in pos_occ:\n",
    "                del pos_occ[key]\n",
    "            if key in neu_occ:\n",
    "                del neu_occ[key]\n",
    "\n",
    "print(len(pos_occ),len(neg_occ),len(neu_occ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "2 1\n",
      "1 1\n",
      "1 1\n",
      "3 2\n",
      "3 1\n",
      "2 1\n",
      "5 1\n",
      "1 1\n",
      "2 2\n",
      "1 1\n",
      "3 1\n",
      "1 2\n",
      "1 2\n",
      "2 1\n",
      "{'bold', 'protective', 'repentant', 'tough', 'assertive', 'determined', 'serious', 'precise', 'competitive', 'transparent', 'obedient', 'spontaneous', 'mannered', 'trendy', 'meticulous'}\n",
      "{'thorough', 'protective', 'daring', 'observant', 'perceptive', 'subtle', 'relaxed', 'calm', 'simple', 'careful', 'scrupulous', 'intuitive', 'serious', 'discreet', 'playful', 'insightful', 'meticulous'}\n",
      "{'ritualistic', 'protective', 'quiet', 'dogmatic', 'stiff', 'conformist', 'cautious', 'strange', 'secretive', 'quirky', 'opinionated', 'serious', 'picky', 'fanciful', 'unsophisticated', 'meticulous', 'stern'}\n"
     ]
    }
   ],
   "source": [
    "def find_repeated_keys(dict1, dict2):\n",
    "    keys1 = set(dict1.keys())\n",
    "    keys2 = set(dict2.keys())\n",
    "    repeated_keys = keys1.intersection(keys2)\n",
    "    return repeated_keys\n",
    "\n",
    "# print(len(pos_occ),len(neg_occ),len(neu_occ))\n",
    "out1 = find_repeated_keys(pos_occ, neg_occ)\n",
    "for key in out1:\n",
    "    print(pos_occ[key], neg_occ[key])\n",
    "out2 = find_repeated_keys(pos_occ, neu_occ)\n",
    "out3 = find_repeated_keys(neu_occ, neg_occ)\n",
    "print(out1)\n",
    "print(out2)\n",
    "print(out3)\n",
    "# print(pos_occ[\"meticulous\"],neg_occ[\"meticulous\"], neu_occ[\"meticulous\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem1 = ['bold', 'protective', 'repentant', 'tough', 'assertive', 'determined', 'serious', 'precise', 'transparent', 'obedient', 'spontaneous', 'mannered', 'trendy', 'meticulous']\n",
    "rem2 = ['competitive']\n",
    "for i in rem1:\n",
    "    del neg_occ[i]\n",
    "\n",
    "for i in rem2:\n",
    "    del pos_occ[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem1 = ['thorough', 'protective', 'daring', 'observant', 'perceptive', 'subtle', 'relaxed', 'calm', 'simple', 'careful', 'scrupulous', 'intuitive', 'serious', 'discreet', 'playful', 'insightful', 'meticulous']\n",
    "for i in rem1:\n",
    "    del neu_occ[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem1 = ['ritualistic', 'quiet', 'dogmatic', 'stiff', 'conformist', 'strange', 'secretive', 'quirky', 'opinionated', 'unsophisticated', 'picky', 'fanciful', 'stern']\n",
    "rem2 = ['cautious']\n",
    "for i in rem1:\n",
    "    del neu_occ[i]\n",
    "for i in rem2:\n",
    "    del neu_occ[i]\n",
    "    del neg_occ[i]\n",
    "pos_occ['cautious'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "def find_repeated_keys(dict1, dict2):\n",
    "    keys1 = set(dict1.keys())\n",
    "    keys2 = set(dict2.keys())\n",
    "    repeated_keys = keys1.intersection(keys2)\n",
    "    return repeated_keys\n",
    "\n",
    "# print(len(pos_occ),len(neg_occ),len(neu_occ))\n",
    "out1 = find_repeated_keys(pos_occ, neg_occ)\n",
    "out2 = find_repeated_keys(pos_occ, neu_occ)\n",
    "out3 = find_repeated_keys(neu_occ, neg_occ)\n",
    "print(out1)\n",
    "print(out2)\n",
    "print(out3)\n",
    "# print(pos_occ[\"meticulous\"],neg_occ[\"meticulous\"], neu_occ[\"meticulous\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "with open(\"sets/traits_scores.csv\", 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Trait', 'Score'])  # Write header\n",
    "\n",
    "    for key, value in pos_occ.items():\n",
    "        writer.writerow([key, 1])\n",
    "    for key, value in neg_occ.items():\n",
    "        writer.writerow([key, -1])\n",
    "    for key, value in neu_occ.items():\n",
    "        writer.writerow([key, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827 1015 72\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_occ),len(neg_occ),len(neu_occ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
